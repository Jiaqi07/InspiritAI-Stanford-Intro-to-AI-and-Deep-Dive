{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Alan's Copy of Advanced_StudentCopy_Master_DoNotEdit_NN_ConscientiousCars.ipynb","provenance":[{"file_id":"1h-IefuHmRzrzeTfZT7B2-lWxH1gdkjEQ","timestamp":1626386513295}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GtaAOpZCsqvp"},"source":["<font color=\"#de3023\"><h1><b>MAKE A COPY OF THIS NOTEBOOK SO YOUR EDITS ARE SAVED</b></h1></font>"]},{"cell_type":"markdown","metadata":{"id":"Sq-JhCcLpBwS"},"source":["\n","We work for CC: ConscientiousCars, where we help self-driving vehicles be more conscientious of their surroundings. Our cars have been very good at recognizing and avoiding humans. They haven't, however, been capable of recognizing dogs. Since dogs are man's best friend and will always be where we humans are, we want our cars to know if a dog is on the road in front of them and avoid the dog!\n","\n","The first step to avoiding these cute puppers is **knowing if a pupper is in front of the car**. So today we will **build a detector that can tell when our car sees a dog or not**!\n","\n"]},{"cell_type":"code","metadata":{"id":"uhNVum16scIW","executionInfo":{"status":"ok","timestamp":1626386539531,"user_tz":300,"elapsed":2517,"user":{"displayName":"Alan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxH6M230Lrt026zWwze2LSG8VHOwo5N6hjMEVA=s64","userId":"00847708095683171844"}}},"source":["#@title Run this to load some packages and data! { display-mode: \"form\" }\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn import model_selection\n","from sklearn.metrics import accuracy_score\n","from collections import Counter\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D\n","from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","\n","def categorical_to_numpy(labels_in):\n","  labels = []\n","  for label in labels_in:\n","    if label == 'dog':\n","      labels.append(np.array([1, 0]))\n","    else:\n","      labels.append(np.array([0, 1]))\n","  return np.array(labels)\n","\n","def one_hot_encoding(input):\n","  output = np.array(input)\n","  output = np.zeros((input.size, input.max()+1))\n","  output[np.arange(input.size),input] = 1\n","  \n","  return output\n","\n","\n","def load_data():\n","  # Run this cell to download our data into a file called 'cifar_data'\n","  import gdown\n","  # gdown.download('https://drive.google.com/uc?id=1-BjeqccJdLiBA6PnNinmXSQ6w5BluLem','cifar_data','True'); # dogs v road;\n","  !wget -O cifar_data https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n","\n","  # now load the data from our cloud computer\n","  import pickle\n","  data_dict = pickle.load(open( \"cifar_data\", \"rb\" ));\n","  \n","  data   = data_dict['data']\n","  labels = data_dict['labels']\n","  \n","  return data, labels\n","\n","def plot_one_image(data, labels, img_idx):\n","  from google.colab.patches import cv2_imshow\n","  import cv2\n","  import matplotlib.pyplot as plt\n","  my_img   = data[img_idx, :].squeeze().reshape([32,32,3]).copy()\n","  my_label = labels[img_idx]\n","  print('label: %s'%my_label)\n","  fig, ax = plt.subplots(1,1)\n","\n","  img = ax.imshow(my_img, extent=[-1,1,-1,1])\n","\n","  x_label_list = [0, 8, 16, 24, 32]\n","  y_label_list = [0, 8, 16, 24, 32]\n","\n","  ax.set_xticks([-1, -0.5, 0, 0.5, 1])\n","  ax.set_yticks([-1, -0.5, 0, 0.5, 1])\n","\n","  ax.set_xticklabels(x_label_list)\n","  ax.set_yticklabels(y_label_list)\n","\n","  fig.show(img)\n","  \n","def CNNClassifier(num_epochs=30, layers=5, dropout=0.5):\n","  def create_model():\n","    model = Sequential()\n","    model.add(Reshape((32, 32, 3)))\n","    \n","    for i in range(layers):\n","      model.add(Conv2D(32, (3, 3), padding='same'))\n","      model.add(Activation('relu'))\n","    \n","    model.add(Conv2D(32, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(dropout / 2.0))\n","\n","    model.add(Conv2D(64, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(64, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(dropout / 2.0))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(dropout))\n","    model.add(Dense(2))\n","    model.add(Activation('softmax'))\n","\n","    # initiate RMSprop optimizer\n","    opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n","\n","    # Let's train the model using RMSprop\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=opt,\n","                  metrics=['accuracy'])\n","    return model\n","  return KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=10, verbose=2)\n","\n","def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n","    history = history.history\n","    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n","    history = pd.DataFrame.from_dict(history)\n","\n","    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n","\n","    if not ax:\n","      f, ax = plt.subplots(1,1)\n","    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n","    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n","    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n","    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n","    ax.legend(loc = 1)    \n","    ax.set_ylim([0.4, 1])\n","\n","    ax.set_xlabel(xlabel)\n","    ax.set_ylabel('Accuracy (Fraction)')\n","    \n","    plt.show()"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EsGDD5lvQoBZ"},"source":["In this notebook, you'll:\n","- Explore the cars vs. roads dataset\n","- Train a simple K-neighbors classifier for computer vision\n","- Train neural nets to tell dogs from roads\n","- Improve your model with convolutional neural networks!\n","- (Optional challenge) Use saliency map to implement explainable AI."]},{"cell_type":"markdown","metadata":{"id":"1QxGsnvhnn8R"},"source":["# Understanding our data"]},{"cell_type":"markdown","metadata":{"id":"btr24O6Hqgo6"},"source":["Our cars are very attentive and always have their eyes on the road.\n","\n","Every second, they're streaming in data about the street, including video.\n","\n","From this video data, we want our car to tell: is there 'road' or 'dog' in front of it?\n","\n","Lucky for us, we have a dataset of dog and road images already prepared! Let's start by reading that *labeled* data in. \n"]},{"cell_type":"code","metadata":{"id":"MmZbrZoKnthN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626386548006,"user_tz":300,"elapsed":260,"user":{"displayName":"Alan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxH6M230Lrt026zWwze2LSG8VHOwo5N6hjMEVA=s64","userId":"00847708095683171844"}},"outputId":"fd142272-6a64-4827-a423-e7eb3611727f"},"source":["# load our data \n","data, labels = load_data()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2021-07-15 22:02:27--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.128, 74.125.195.128, 142.250.107.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3689015 (3.5M) [application/octet-stream]\n","Saving to: ‘cifar_data’\n","\n","\rcifar_data            0%[                    ]       0  --.-KB/s               \rcifar_data          100%[===================>]   3.52M  --.-KB/s    in 0.02s   \n","\n","2021-07-15 22:02:27 (220 MB/s) - ‘cifar_data’ saved [3689015/3689015]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AGO0FFnqdFne"},"source":["Let's look at an image of a dog!\n","\n","Try changing the number below. What does it do?\n","\n"]},{"cell_type":"code","metadata":{"id":"csXB_FPMrx1D","colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"status":"ok","timestamp":1626386588161,"user_tz":300,"elapsed":780,"user":{"displayName":"Alan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxH6M230Lrt026zWwze2LSG8VHOwo5N6hjMEVA=s64","userId":"00847708095683171844"}},"outputId":"5de9f75c-9ef2-44ea-8e88-ddff07b2cdaa"},"source":["plot_one_image(data, labels, 800) #change this number"],"execution_count":4,"outputs":[{"output_type":"stream","text":["label: road\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"ZYRzHTxVdSTG"},"source":["**Discuss:** Why might we be using such blurry images?\n","\n","Next, let's try a road image. Again, try changing the number:"]},{"cell_type":"code","metadata":{"id":"CsRj6BAqs25Y"},"source":["plot_one_image(data, labels, 700) #change this number"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0Qx4UYxdbTK"},"source":["How many images do we have?"]},{"cell_type":"code","metadata":{"id":"6LQXCiGmAmz-"},"source":["print (len(data))\n","\n","print(Counter(labels))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OojOPMbLAl2B"},"source":["The dataset is organized such that there are 600 images of dogs and 600 images of roads."]},{"cell_type":"markdown","metadata":{"id":"9Sz2c5LlU7Sj"},"source":["#### Optional Exercise: Examining More Images\n","\n","**Look at a few more images of both classes.** \n","\n","Try using a `for` loop to look at 5 images!"]},{"cell_type":"code","metadata":{"id":"DkcqdB2ZVoNc"},"source":["### YOUR CODE HERE\n","\n","\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PHS0E_3wt0RS"},"source":["##Understanding our Data Representation\n","\n","In an image each pixel is denoted by 3 numbers that represent the intensity value of that pixel (0 - 255) for each color channel (R, G, and B). Below we \n","see a list of numbers for each image that represent the intensity values. \n"]},{"cell_type":"code","metadata":{"id":"DlgF6jWit9jz"},"source":["print('One image looks like: ')\n","print(data[0])\n","print(\"Length of list: \", len(data[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gPu7IDsZU_On"},"source":["**Discuss:** What does each number mean? Can you explain the length of the list?\n","\n","**Exercise:**\n","Fill in the right values for the image width, image height, and number of color channels to calculate the right number of pixels."]},{"cell_type":"code","metadata":{"id":"YWBX6fWUui4R"},"source":["img_height = 0 #Change this\n","img_width = 0 #Change this\n","color_channels = 0 #Change this\n","\n","print (\"Each image is\", img_height, 'x', img_width, 'pixels.')\n","print (\"Each pixel has\", color_channels, \"channels for red, green, blue.\")\n","print (\"This gives a total of\", img_height * img_width * color_channels, \"intensity values per image.\")\n","print (\"Should be\", len(data[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-haNvnOwt-YE"},"source":["We use these values as **inputs** to predict an **output** label: 'dog' or 'road'!\n","\n","Here's what our entire dataset looks like:"]},{"cell_type":"code","metadata":{"id":"JZIiCuBrvS6z"},"source":["print ('Data shape:', data.shape)\n","print ('Data:', data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tUjr5CKnhvtg"},"source":["#A Simple Machine Learner"]},{"cell_type":"markdown","metadata":{"id":"hPskDCqlzOEE"},"source":["We want to create a machine learning model that can tell us whether a new image is either a dog or a road.\n","\n","We will give our model a training manual of data and labels that it will study or train on.\n","\n","We then check how well our model is doing on a test, where it is given data and told to predict their labels.\n"]},{"cell_type":"markdown","metadata":{"id":"S0tDoNWFVVYB"},"source":["Building a KNN"]},{"cell_type":"markdown","metadata":{"id":"Q8_JZ9PVzKzr"},"source":["Let's start by using the `KNeighborsClassifier` model.\n","\n","**Playground:** Explore [this demo](http://vision.stanford.edu/teaching/cs231n-demos/knn/) to understand what the KNN model is doing! \n","\n","**Exercise:** Below, please build, train, and measure the accuracy of your own KNN model. Experiment with changing the number of neighbors!"]},{"cell_type":"code","metadata":{"id":"ZFOgS2VEyTkH"},"source":["X_train, X_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2)\n","### YOUR CODE HERE\n","\n","\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uU48O9l18_-C"},"source":["##Predicting on images\n","\n","We can use our trained model to predict whether our car is seeing a `dog` or `road`. Let's try this out - experiment with different images!\n"]},{"cell_type":"code","metadata":{"id":"Az1_moLl9E0B"},"source":["# Specify which image you want to show\n","image_id = 100 #Change this!\n","\n","# Visualize the image\n","plot_one_image(X_test, y_test, image_id)\n","\n","# Use the model to predict what this might be and print it\n","print('prediction:', knn.predict([X_test[image_id]])[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4oW_Wb-1CTfB"},"source":["## Choosing a value of k\n","\n","**Exercise** Determine the optimal value of \"K\" for our data. Use a for-loop to loop through different values of \"K\". In particular, *at the very least* try K = 1, 3, 5, 10, 20, and 30. For each of these values of \"K\", define a new KNN model, train it, and evaluate the accuracy."]},{"cell_type":"code","metadata":{"id":"OrZK_qoAZOAd"},"source":["### YOUR CODE HERE\n","\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AZ9uYgKMCX-z"},"source":["**Discuss:** What are the advantages and disadvantages of using a bigger vs. smaller **k**? What is the optimal value?"]},{"cell_type":"markdown","metadata":{"id":"j09evSD_YfJ4"},"source":["## (Optional) Understanding our mistakes\n","\n","Our classifications are OK, but are they good enough for our conscientious cars?\n","\n","Let's put on our detective hats to determine the root causes of the incorrect classifications!\n","\n","**Exercise:** Below, please print out 4 images of true positives, 4 images of true negatives, 4 images of false positives, and 4 images of false negatives. What are the reasons for failure (both for false positives and false negatives)? "]},{"cell_type":"code","metadata":{"id":"xWy1S_gyGoJT"},"source":["#True Positives (code provided)\n","tp_count = 0\n","print (\"TRUE POSITIVES\")\n","i = 0\n","while tp_count < 4 and i < len(X_test):\n","  prediction = knn.predict([X_test[i]])[0] \n","  if prediction == y_test[i] and prediction == 'dog':\n","    plot_one_image(X_test, y_test, i)\n","    tp_count += 1\n","  i += 1\n","\n","#False Positives\n","#YOUR CODE HERE\n","\n","#True Negatives\n","#YOUR CODE HERE\n","\n","#False Negatives\n","#YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nSx8HEhHKxFd"},"source":["**Discuss:** What patterns did you notice? What are some reasons that the model makes mistakes?"]},{"cell_type":"markdown","metadata":{"id":"doLXp1Ot8D2C"},"source":["#Neural Networks\n","Now, let's create some new models using neural networks!\n","\n","You can play around with [TensorFlow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.62283&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularization_hide=true&regularizationRate_hide=true&learningRate_hide=true&batchSize_hide=true&stepButton_hide=true&activation_hide=true) to get a feel for how neural nets work."]},{"cell_type":"markdown","metadata":{"id":"u9iFe-B4zqQA"},"source":["To build a simple neural network, we use `MLPClassifier` from scikit-learn. We will play with the **number of neurons** and the **number of hidden layers** to adjust the complexity of our model, just like we did in Playground!\n","\n","**Example 1:**\n","Here's how we create a neural network with 1 hidden layer of 3 neurons.\n","\n","`nnet = MLPClassifier(hidden_layer_sizes=(3)) `\n","\n","**Example 2:**\n","\n","Here's how we create a neural network with 2 hidden layers: one of 3 neurons and one of 4 neurons.\n","\n","`nnet = MLPClassifier(hidden_layer_sizes=(3, 4)) `"]},{"cell_type":"code","metadata":{"id":"x4XblMWBzm96"},"source":["# Create and train our multi layer perceptron model\n","nnet = MLPClassifier(hidden_layer_sizes=(3), max_iter= 10000000)  ## How many hidden layers? How many neurons does this have?\n","nnet.fit(X_train, y_train)\n","\n","# Predict what the classes are based on the testing data\n","predictions = nnet.predict(X_test)\n","\n","# Print the score on the testing data\n","print(\"MLP Testing Set Score:\")\n","print(accuracy_score(y_test, predictions)*100)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J1QYZTxq0RCV"},"source":["**How well did your neural network perform?** \n","\n","Multilayer perceptrons are more complex models and it can be difficult to find the right \"settings\" for them. It takes some trial and error!"]},{"cell_type":"markdown","metadata":{"id":"nX27P2eY0yqQ"},"source":["**Exercise: try the following out and see how well you can get your network to do!**\n","* Train a 1 layer, 10 neuron network for practice\n","* Change the number of neurons and/or add layers to see how well you can do\n","* Increase or decrease the number of iterations"]},{"cell_type":"code","metadata":{"id":"_nPOrTN-JMYk"},"source":["#YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hXud5MuBXqzo"},"source":["###Automating our Experiments \n","\n","**Exercise:** Similar to what you did for KNNs, use a for loop to automate your investigation. Explore different numbers of hidden layers, the size of the hidden layers, and the number of iterations! How well can you get your network performing?"]},{"cell_type":"code","metadata":{"id":"owrF6cDvX0HX"},"source":["### YOUR CODE HERE\n","\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"37O_VE_D1Bdy"},"source":["# Models for Vision: Convolutional Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"QskPD4RT1GlK"},"source":["There is a famous type of neural network known as convolutional neural networks (CNNs). These types of neural networks work particularly well on problems to do with computer vision. Let's try one out!\n","\n","To load up a simple CNN on scikit-learn, just run:\n","\n","`cnn = CNNClassifier(num_epochs=N)`\n","\n","The `num_epochs` represents how many times the neural network passes through the training dataset. \n","\n","We'll need to change our data to floats (decimal numbers):"]},{"cell_type":"code","metadata":{"id":"kpf8uxMsT7N1"},"source":["# convert our data to floats for our CNN\n","X_train = X_train.astype(float)\n","X_test = X_test.astype(float)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GqrfI4JiVeFr"},"source":["###Training Your CNN\n","**Exercise:** Please train and test your CNN below!"]},{"cell_type":"code","metadata":{"id":"dSwghlVU4WTy"},"source":["### YOUR CODE HERE\n","# Create and train our cnn\n","\n","# Predict what the classes are based on the testing data\n","\n","# Print the score on the testing data\n","\n","\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KGWpgsVXP1ut"},"source":["**Discuss: Is this CNN good enough to use in practice?** \n","\n","CNNs typically perform better than basic Neural Networks on vision problems - but like basic Neural Networks, they aren't always consistent in their results and are sensitive to a number of factors. \n","\n","If you're interested in learning more about CNNs, spend some time exploring the [CNN Explainer](https://poloclub.github.io/cnn-explainer/)!\n","\n","**Report to the class your highest model accuracy.**\n","\n","**Bonus Question:** Each of you might see a different max accuracy. Can you think of why that might be?\n"]},{"cell_type":"markdown","metadata":{"id":"c-XRh5Y5P_CL"},"source":["## Training and Validation Curves\n","\n","An important aspect of training neural networks is to prevent overfitting. **How do you know when your model is overfitting?**\n","\n","To plot our model's history, we can train it with\n","```\n","history = model.fit(X_train.astype(float), categorical_to_numpy(y_train), validation_data=(X_test.astype(float), categorical_to_numpy(y_test)))\n","```\n","\n","and then use\n","```\n","plot_acc(history)\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"8eaFvE2PQEFe"},"source":["**Exercise:** Train a CNN model and plot a train vs. test curve.\n","\n","**After how many epochs does the model begin to overfit?** Overfitting occurs when the validation accuracy starts to drop below the training accuracy."]},{"cell_type":"code","metadata":{"id":"OsVAasDbjARJ"},"source":["### YOUR CODE HERE\n","\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RVzEpI_xWpE5"},"source":["### Hopefully your CNN worked *very* well! We want to keep the doggos as safe as they can be.\n","\n","![](https://images.pexels.com/photos/316/black-and-white-animal-dog-pet.jpg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940)"]},{"cell_type":"markdown","metadata":{"id":"7Y1wGoQPm2Ko"},"source":["# Challenge Exercise: Explainability through Saliency Maps"]},{"cell_type":"markdown","metadata":{"id":"UnGTR2Vdb08i"},"source":["Neural networks have achieved incredible results in many fields. But they have a big problem: it’s very difficult to explain exactly why a neural network makes the decisions it does. This makes it difficult to trust them in high-stakes applications like medicine, self-driving cars, and criminal justice - would you trust an AI that diagnosed you with a disease, but couldn’t explain why?\n","\n","Other classifiers are much more explainable:\n","\n","*   With logistic regression, we can see the coefficient (importance) attached to each input feature.\n","*   With a decision tree, we can trace a particular decision down the tree.\n","*   With KNN, we can examine the nearby neighbors.\n","\n","Our CNN, above, works well. For example, let's try choosing an image from our dataset and classifying it."]},{"cell_type":"code","metadata":{"id":"HmU6Peb7m67F"},"source":["image_index = 70 #pick any image you'd like\n","input_image = X_test[image_index] \n","print (input_image.shape) \n","print (input_image) #How many numbers are there? What does each represent?\n","\n","plt.imshow(input_image.reshape(32,32,3).astype(int))\n","plt.show()\n","\n","print ('Classification:')\n","print(cnn.predict(np.array([input_image]))) #Our predict function expects a 2D array.\n","#0 means dog, 1 means road"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c6P7DX_WcfOU"},"source":["But why did the CNN reach that decision? It’s really hard to give a clear answer! The CNN relies on multiplying input features by the weights it has set. You can print out and look at the hundreds of weights:\n"]},{"cell_type":"code","metadata":{"id":"w8M8UZCgcpqO"},"source":["#Warning: expect a large output!\n","for layer_weights in history.model.weights:\n","  print (layer_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SR42boMgczoF"},"source":["Unfortunately, that probably didn’t help you make a useful explanation.\n","\n","Researchers are currently studying ways to make neural networks more explainable. One approach is using **saliency maps** to figure out the saliency (importance) of each individual pixel. Check out a demo [here](https://lrpserver.hhi.fraunhofer.de/image-classification). Intuitively, we're trying to understand the neural network by tracking what it \"pays attention\" to, in the same way that psychologists study babies' cognition by [tracking what babies look at](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3259733/).\n","\n","In this exercise, we're going to build a simple version of a saliency map for the image you chose above. We'll see what pixels were most important in helping the network make its classification.\n","\n","To do this, we'll investigate the effects of changing each pixel a little bit. If changing a particular pixel changes the result a lot, we conclude that pixel must be important for classifying. If changing that pixel doesn't change the result, we conclude that pixel is unimportant.\n"]},{"cell_type":"markdown","metadata":{"id":"0RpZL6ChfLZ6"},"source":["We're going to use the raw predicted probabilities, rather than the final classification."]},{"cell_type":"code","metadata":{"id":"gkdMS7sJfR6j"},"source":["pred = cnn.predict_proba(np.array([input_image])) #What does each number mean?\n","print (pred)\n","dog_prob = pred[0][0] #This is the probability we'll use (if we know dog prob, we know the classification)\n","\n","print ('Probability of dog:')\n","print (dog_prob)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xla3j0R1geJY"},"source":["Now, we need to calculate the saliency for each pixel (really, each R/G/B value). The core idea is that a pixel's saliency is the average value of \n","\n"," $D = |\\frac{\\Delta probability}{\\Delta pixel}|$\n"," \n"," where $\\Delta$ is the amount of change. If a small change in the pixel value results in a large change in the probability (either up or down), we know this pixel is important. If you've seen derivatives in calculus, this idea should feel familiar.\n","\n","Here's the game plan:\n","\n","*   Consider each pixel value in turn: R, G, B, then the next pixel.\n","*   Make a copy of the image array before you change anything!\n","*   Make the pixel value larger or smaller by various amounts. Each time, find the CNN's prediction with the changed value, and calculate the value of D.\n","*   Repeat the previous step a few times, and calculate the pixel's saliency: the average value of D.\n","*   Store the saliency of each pixel in a list, so that we can visualize it later.\n","\n","Try it below! (Warning: this code might be very slow. As a further challenge, try to speed it up!)\n"]},{"cell_type":"code","metadata":{"id":"RnABhKUJmNCF"},"source":["saliencies = [] #eventually, will be the same size as input_image\n","\n","for index, pixel in enumerate(input_image):\n","  #index counts up from 0, pixel is between 0 and 255\n","  \n","  if index%100 == 0: #will track progress - this might take a while\n","    print (index)\n","  \n","  changed_input = input_image.copy() #make sure not to change the original input_image!\n","  \n","  #YOUR CODE HERE:\n","  #In changed_input, change the value of this pixel by some amount.\n","  #Use the CNN to classify changed_input.\n","  #Calculate the value of D.\n","  #Repeat with various-size changes, and calculate saliency as the average D.\n","  saliency = 0 #Change this!\n","\n","  saliencies.append(saliency)\n","\n","print (saliencies)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SJEAJ5VinTIZ"},"source":["You'll notice that your saliencies are probably very small values, since each individual pixel has a small effect on the output. \n","Here are the current min and max:"]},{"cell_type":"code","metadata":{"id":"S5vRrciYnZgk"},"source":["sal_array = np.array(saliencies)\n","print (sal_array.min(), sal_array.max())\n","print (sal_array.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwQfwv6rnl--"},"source":["To plot the saliencies, we need to do some arithmetic to transform them to a range of 0 to 1. Can you explain the function of each line?"]},{"cell_type":"code","metadata":{"id":"XL_W9k0W0Sai"},"source":["sal_array = np.array(saliencies)\n","sal_array = sal_array - sal_array.min()\n","#TODO print min and max\n","\n","sal_array = sal_array/sal_array.max()\n","#TODO print min and max\n","\n","#Can you perform this transformation in a single line of code?\n","\n","print (sal_array.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OvFKoff4n_gf"},"source":["Finally, we can plot our saliency map!\n","\n","If you're not getting great results, try experimenting with how much you're changing the pixel values."]},{"cell_type":"code","metadata":{"id":"2vANcgvj1Pvc"},"source":["#Plot our original image\n","plt.imshow(input_image.reshape(32,32,3).astype(int))\n","plt.show()\n","\n","#Plot our saliency map: the brighter, the higher the saliency\n","plt.imshow(sal_array.reshape(32,32,3))\n","plt.show()\n","\n","#Plot our saliency map superimposed on the image\n","plt.imshow(input_image.reshape(32,32,3).astype(int))\n","plt.imshow(sal_array.reshape(32,32,3),alpha=0.6)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fistwbaDp56y"},"source":["We now have some insight into our neural network! We know which pixels matter in its decisions. \n","\n","You can experiment with the definition of saliency we used above; you might come up with a better way to measure it!"]}]}